{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "name": "New AIDA-X Model Trainer",
            "provenance": [],
            "collapsed_sections": []
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.x"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "initial_markdown_cell"
            },
            "source": [
                "# New AIDA-X Model Trainer for Colab\n",
                "This notebook will guide you through training a new model using the `new_model_trainer`.\n\n",
                "**Instructions:**\n",
                "1.  Make a copy of this notebook to your Google Drive (`File > Save a copy in Drive`).\n",
                "2.  Follow the steps in each section, executing the code cells by pressing Shift+Enter or clicking the play button.\n",
                "3.  Ensure your audio data and configuration files are stored in Google Drive for easy access.\n",
                "4.  Adjust parameters using the form fields provided in the cells."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": { "id": "setup_markdown_header" },
            "source": [
                "## 1. Setup Environment\n",
                "This section clones the project repository (if you're running this notebook directly from GitHub or a fresh Colab instance), installs necessary dependencies from `requirements.txt`, checks for GPU availability, and mounts your Google Drive for data access."
            ]
        },
        {
            "cell_type": "code",
            "metadata": { "id": "setup_code_cell" },
            "source": [
                "#@markdown ### (RUN CELL) 1.1: Initial Setup, Dependencies, and Google Drive\n",
                "#@markdown This cell will:\n",
                "#@markdown 1. Clone the repository (if not already in the correct environment).\n",
                "#@markdown 2. Change directory to `new_model_trainer`.\n",
                "#@markdown 3. Install required Python packages from `requirements.txt`.\n",
                "#@markdown 4. Check for GPU and mount Google Drive.\n",
                "\n",
                "import os\n",
                "import subprocess\n",
                "import sys\n",
                "\n",
                "# --- Repository Setup ---\n",
                "REPO_NAME = \"Automated-GuitarAmpModelling\" # The name of the repository\n",
                "COLAB_CONTENT_PATH = \"/content\"\n",
                "REPO_PATH = os.path.join(COLAB_CONTENT_PATH, REPO_NAME)\n",
                "NEW_TRAINER_DIR_NAME = \"new_model_trainer\" # The specific subdirectory we need to be in\n",
                "TARGET_DIR = os.path.join(REPO_PATH, NEW_TRAINER_DIR_NAME)\n",
                "\n",
                "print(f\"Expected final directory: {TARGET_DIR}\")\n",
                "\n",
                "if os.getcwd() == TARGET_DIR:\n",
                "    print(f\"Already in the correct directory: {os.getcwd()}\")\n",
                "    print(\"Pulling latest changes from repository...\")\n",
                "    result = subprocess.run([\"git\", \"pull\"], capture_output=True, text=True)\n",
                "    print(result.stdout)\n",
                "    if result.stderr and result.returncode != 0 : print(f\"Git pull stderr: {result.stderr}\")\n",
                "elif os.path.exists(TARGET_DIR):\n",
                "    print(f\"Repository '{REPO_NAME}' and subdirectory '{NEW_TRAINER_DIR_NAME}' found.\")\n",
                "    os.chdir(TARGET_DIR)\n",
                "    print(f\"Changed directory to: {os.getcwd()}\")\n",
                "    print(\"Pulling latest changes from repository...\")\n",
                "    result = subprocess.run([\"git\", \"pull\"], capture_output=True, text=True)\n",
                "    print(result.stdout)\n",
                "    if result.stderr and result.returncode != 0 : print(f\"Git pull stderr: {result.stderr}\")\n",
                "else:\n",
                "    print(f\"Cloning repository '{REPO_NAME}' into {COLAB_CONTENT_PATH}...\")\n",
                "    GIT_CLONE_URL = \"https://github.com/AidaDSP/Automated-GuitarAmpModelling.git\"\n",
                "    \n",
                "    # Clone outside the target dir first, then cd\n",
                "    if os.path.exists(REPO_PATH):\n",
                "        print(f\"Repository path {REPO_PATH} already exists but not in TARGET_DIR. Removing and re-cloning for clean state.\")\n",
                "        subprocess.run([\"rm\", \"-rf\", REPO_PATH], check=True)\n",
                "        \n",
                "    result = subprocess.run([\"git\", \"clone\", GIT_CLONE_URL, REPO_PATH], capture_output=True, text=True)\n",
                "    if result.returncode == 0:\n",
                "        print(\"Repository cloned successfully.\")\n",
                "        os.chdir(TARGET_DIR)\n",
                "        print(f\"Changed directory to: {os.getcwd()}\")\n",
                "    else:\n",
                "        print(f\"ERROR: Cloning repository failed!\\nStdout:\\n{result.stdout}\\nStderr:\\n{result.stderr}\")\n",
                "        sys.exit(\"Failed to clone repository.\")\n",
                "\n",
                "# --- Install Dependencies ---\n",
                "print(\"\\nInstalling dependencies from requirements.txt...\")\n",
                "requirements_path = \"requirements.txt\"\n",
                "if os.path.exists(requirements_path):\n",
                "    try:\n",
                "        # Ensure pip is up-to-date\n",
                "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"], check=True, capture_output=True, text=True)\n",
                "        # Install requirements\n",
                "        result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_path], check=True, capture_output=True, text=True)\n",
                "        print(\"Dependencies installed successfully.\")\n",
                "        # print(result.stdout) # Optionally print stdout for installed packages\n",
                "    except subprocess.CalledProcessError as e:\n",
                "        print(f\"ERROR: Installing dependencies failed!\\nExit Code: {e.returncode}\\nStdout:\\n{e.stdout}\\nStderr:\\n{e.stderr}\")\n",
                "        sys.exit(\"Failed to install dependencies.\")\n",
                "else:\n",
                "    print(f\"ERROR: {requirements_path} not found in {os.getcwd()}. Cannot install dependencies.\")\n",
                "    sys.exit(\"requirements.txt not found.\")\n",
                "\n",
                "# --- PyTorch/GPU Check ---\n",
                "print(\"\\nChecking PyTorch and GPU availability...\")\n",
                "try:\n",
                "    import torch\n",
                "    print(f\"PyTorch version: {torch.__version__}\")\n",
                "    if torch.cuda.is_available():\n",
                "        print(f\"CUDA is available. GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    elif torch.backends.mps.is_available():\n",
                "        print(\"MPS is available for PyTorch (Apple Silicon GPU).\")\n",
                "    else:\n",
                "        print(\"No GPU (CUDA or MPS) found by PyTorch. Training will use CPU.\")\n",
                "except ImportError:\n",
                "    print(\"ERROR: PyTorch is not installed. Please ensure dependencies were installed correctly.\")\n",
                "    sys.exit(\"PyTorch not found after installation attempt.\")\n",
                "\n",
                "# --- Mount Google Drive ---\n",
                "print(\"\\nMounting Google Drive at /content/drive...\")\n",
                "try:\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive', force_remount=True)\n",
                "    print(\"Google Drive mounted successfully.\")\n",
                "except ImportError:\n",
                "    print(\"Could not import Google Drive module. This notebook is intended to be run in Google Colab.\")\n",
                "except Exception as e:\n",
                "    print(f\"An error occurred while mounting Google Drive: {e}\")\n",
                "\n",
                "print(\"\\n--- Setup cell complete. --- \")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": { "id": "data_prep_markdown_header" },
            "source": [
                "## 2. Data Preparation\n\n",
                "This cell handles the setup of your training data. It will:\n",
                "1. Ask for the path to your main data directory in Google Drive.\n",
                "2. Ask for the name of your JSON training configuration file (which should be inside the directory specified above).\n",
                "3. Copy your JSON configuration to Colab's local storage.\n",
                "4. Parse this JSON config to find `dataset_items`.\n",
                "5. For each item, copy the specified `input_path` and `target_path` audio files from Google Drive to Colab's local storage.\n",
                "6. Rewrite the paths in `dataset_items` (and `output_dir`) in the configuration to point to these local Colab paths.\n",
                "7. Save this modified configuration as `effective_training_config.json` in Colab, which will be used by the training script.\n\n",
                "**Important:**\n",
                "- Your main JSON configuration file (e.g., `my_run_config.json`) must be structured like `new_model_trainer/configs/example_config.json`.\n",
                "- It **must** contain a `dataset_items` list.\n",
                "- Paths within `dataset_items` (`input_path`, `target_path`) can be either:\n",
                "    - Relative to the `DRIVE_DATA_DIR` you specify below (e.g., `DI_audio/input1.wav`).\n",
                "    - Absolute Google Drive paths (e.g., `/content/drive/MyDrive/MyAudio/input1.wav`)."
            ]
        },
        {
            "cell_type": "code",
            "metadata": { "id": "data_prep_code_cell" },
            "source": [
                "# Python code for Data Preparation cell\n",
                "\n",
                "#@markdown ### (RUN CELL) 2.1: Specify Data and Configuration Location\n",
                "#@markdown Mount your Google Drive if you haven't already (the Setup cell should do this).\n",
                "#@markdown Then, provide the path to your main data directory on Google Drive and the name of your JSON configuration file within that directory.\n",
                "\n",
                "DRIVE_DATA_DIR = \"/content/drive/MyDrive/AidaX_Training_Data\" #@param {type: \"string\"}\n",
                "TRAINING_CONFIG_FILENAME = \"my_training_run_config.json\" #@param {type: \"string\"}\n",
                "\n",
                "import os\n",
                "import json\n",
                "import shutil\n",
                "import sys\n",
                "\n",
                "# --- Define local Colab paths ---\n",
                "COLAB_CONFIG_DIR = \"/content/colab_configs\"\n",
                "COLAB_AUDIO_DIR = \"/content/colab_training_audio\"\n",
                "LOCAL_TRAINING_CONFIG_PATH = os.path.join(COLAB_CONFIG_DIR, \"effective_training_config.json\")\n",
                "\n",
                "os.makedirs(COLAB_CONFIG_DIR, exist_ok=True)\n",
                "os.makedirs(COLAB_AUDIO_DIR, exist_ok=True)\n",
                "\n",
                "print(f\"User's Google Drive Data Directory: {DRIVE_DATA_DIR}\")\n",
                "print(f\"User's Training Configuration Filename: {TRAINING_CONFIG_FILENAME}\")\n",
                "\n",
                "# --- Step 1: Copy and Parse the Main JSON Configuration File ---\n",
                "drive_config_path = os.path.join(DRIVE_DATA_DIR, TRAINING_CONFIG_FILENAME)\n",
                "local_temp_config_path = os.path.join(COLAB_CONFIG_DIR, \"original_drive_config.json\")\n",
                "\n",
                "config_data = None # Initialize config_data\n",
                "if not os.path.exists(drive_config_path):\n",
                "    print(f\"ERROR: Main training configuration file not found at: {drive_config_path}\")\n",
                "    sys.exit(\"Configuration file not found in Drive. Please check path and filename.\") \n",
                "else:\n",
                "    print(f\"Copying main configuration file from {drive_config_path} to {local_temp_config_path}\")\n",
                "    shutil.copy(drive_config_path, local_temp_config_path)\n",
                "    try:\n",
                "        with open(local_temp_config_path, 'r') as f:\n",
                "            config_data = json.load(f)\n",
                "        print(\"Successfully loaded main configuration file.\")\n",
                "    except Exception as e:\n",
                "        print(f\"ERROR: Could not parse main training configuration file {local_temp_config_path}. Error: {e}\")\n",
                "        sys.exit(\"Failed to parse configuration file.\")\n",
                "\n",
                "if config_data:\n",
                "    # --- Step 2: Process dataset_items, copy audio, and update paths ---\n",
                "    if 'dataset_items' not in config_data or not isinstance(config_data['dataset_items'], list):\n",
                "        print(\"ERROR: The configuration file must contain a 'dataset_items' list.\")\n",
                "        sys.exit(\"Invalid configuration: missing or malformed dataset_items.\")\n",
                "    if not config_data['dataset_items']:\n",
                "        print(\"ERROR: 'dataset_items' list in configuration is empty. Nothing to process.\")\n",
                "        sys.exit(\"Empty dataset_items list.\")\n",
                "\n",
                "    updated_dataset_items = []\n",
                "    all_files_copied_successfully = True\n",
                "    \n",
                "    # Clear out old audio data if any\n",
                "    print(f\"Clearing local audio directory: {COLAB_AUDIO_DIR}...\")\n",
                "    for item_name in os.listdir(COLAB_AUDIO_DIR):\n",
                "        item_path = os.path.join(COLAB_AUDIO_DIR, item_name)\n",
                "        try:\n",
                "            if os.path.isfile(item_path) or os.path.islink(item_path):\n",
                "                os.unlink(item_path)\n",
                "            elif os.path.isdir(item_path):\n",
                "                shutil.rmtree(item_path)\n",
                "        except Exception as e:\n",
                "            print(f'Failed to delete {item_path}. Reason: {e}')\n",
                "    print(f\"Local audio directory cleared.\")\n",
                "\n",
                "    for i, item in enumerate(config_data['dataset_items']):\n",
                "        original_input_path = item.get('input_path')\n",
                "        original_target_path = item.get('target_path')\n",
                "\n",
                "        if not original_input_path or not original_target_path:\n",
                "            print(f\"WARNING: Skipping item {i} due to missing 'input_path' or 'target_path'.\")\n",
                "            all_files_copied_successfully = False # Mark as not fully successful\n",
                "            continue\n",
                "\n",
                "        full_drive_input_path = original_input_path if original_input_path.startswith(\"/content/drive/\") else os.path.join(DRIVE_DATA_DIR, original_input_path)\n",
                "        full_drive_target_path = original_target_path if original_target_path.startswith(\"/content/drive/\") else os.path.join(DRIVE_DATA_DIR, original_target_path)\n",
                "\n",
                "        if not os.path.exists(full_drive_input_path):\n",
                "            print(f\"ERROR: Input audio file not found for item {i}: {full_drive_input_path}\")\n",
                "            all_files_copied_successfully = False\n",
                "            continue\n",
                "        if not os.path.exists(full_drive_target_path):\n",
                "            print(f\"ERROR: Target audio file not found for item {i}: {full_drive_target_path}\")\n",
                "            all_files_copied_successfully = False\n",
                "            continue\n",
                "        \n",
                "        input_basename = os.path.basename(original_input_path)\n",
                "        target_basename = os.path.basename(original_target_path)\n",
                "        local_input_filename = f\"{i:03d}_input_{input_basename}\"\n",
                "        local_target_filename = f\"{i:03d}_target_{target_basename}\"\n",
                "        \n",
                "        local_colab_input_path = os.path.join(COLAB_AUDIO_DIR, local_input_filename)\n",
                "        local_colab_target_path = os.path.join(COLAB_AUDIO_DIR, local_target_filename)\n",
                "\n",
                "        try:\n",
                "            # print(f\"Copying input: {full_drive_input_path} -> {local_colab_input_path}\")\n",
                "            shutil.copy(full_drive_input_path, local_colab_input_path)\n",
                "            # print(f\"Copying target: {full_drive_target_path} -> {local_colab_target_path}\")\n",
                "            shutil.copy(full_drive_target_path, local_colab_target_path)\n",
                "            \n",
                "            updated_item = item.copy()\n",
                "            updated_item['input_path'] = local_colab_input_path\n",
                "            updated_item['target_path'] = local_colab_target_path\n",
                "            updated_dataset_items.append(updated_item)\n",
                "        except Exception as e:\n",
                "            print(f\"ERROR: Failed to copy files for item {i}. Input: {full_drive_input_path}, Target: {full_drive_target_path}. Error: {e}\")\n",
                "            all_files_copied_successfully = False\n",
                "            continue # Skip this item\n",
                "    \n",
                "    if not updated_dataset_items:\n",
                "        print(\"ERROR: No dataset items were successfully processed or all had errors. Please check paths and file existence in your Google Drive and config.\")\n",
                "        sys.exit(\"Dataset processing failed.\")\n",
                "    elif not all_files_copied_successfully:\n",
                "        print(\"WARNING: Some files could not be copied or were missing. Proceeding with successfully processed items only.\")\n",
                "\n",
                "    config_data['dataset_items'] = updated_dataset_items\n",
                "    \n",
                "    model_name_sanitized = \"\".join(c if c.isalnum() else \"_\" for c in config_data.get('model_name', 'default_model'))\n",
                "    local_output_dir = f\"/content/training_output/{model_name_sanitized}\"\n",
                "    config_data['output_dir'] = local_output_dir \n",
                "    os.makedirs(local_output_dir, exist_ok=True)\n",
                "    print(f\"Output for training run will be in local Colab directory: {local_output_dir}\")\n",
                "\n",
                "    with open(LOCAL_TRAINING_CONFIG_PATH, 'w') as f:\n",
                "        json.dump(config_data, f, indent=4)\n",
                "    print(f\"Effective training configuration with local paths saved to: {LOCAL_TRAINING_CONFIG_PATH}\")\n",
                "    print(\"\\nData preparation cell complete. You can now proceed to 'Training Configuration'.\")\n",
                "    \n",
                "    # Expose the path to the generated config for the next cells\n",
                "    globals()['GLOBAL_COLAB_CONFIG_PATH'] = LOCAL_TRAINING_CONFIG_PATH\n",
                "else:\n",
                "    print(\"ERROR: Main configuration data not loaded in the first place. Cannot proceed.\")\n",
                "    globals()['GLOBAL_COLAB_CONFIG_PATH'] = None\n"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": { "id": "training_config_markdown_header" },
            "source": [
                "## 3. Training Configuration\n\n",
                "This cell allows you to make final adjustments to the training parameters. It loads the `effective_training_config.json` (prepared in the previous step, with localized data paths) and then applies any overrides you specify using the Colab form fields below.\n\n",
                "The final configuration, including your overrides, will be saved back to `effective_training_config.json`, which is then used by the 'Run Training' cell."
            ]
        },
        {
            "cell_type": "code",
            "metadata": { "id": "training_config_code_cell" },
            "source": [
                "# Python code for Training Configuration cell\n",
                "\n",
                "#@markdown ### (RUN CELL) 3.1: Adjust Training Parameters (Optional Overrides)\n",
                "#@markdown This section allows you to override some common settings from your main configuration file (`{{TRAINING_CONFIG_FILENAME}}` loaded in the previous step).\n",
                "#@markdown Leave fields blank or as their default to use the value from your JSON config.\n",
                "\n",
                "#@markdown ---\n",
                "#@markdown **Basic Settings:**\n",
                "MODEL_NAME_OVERRIDE = \"\" #@param {type:\"string\"}\n",
                "#@markdown Enter a specific number of epochs, or -1 to use the config file's value.\n",
                "EPOCHS_OVERRIDE = -1 #@param {type:\"integer\"}\n",
                "#@markdown Enter a specific batch size, or -1 to use the config file's value.\n",
                "BATCH_SIZE_OVERRIDE = -1 #@param {type:\"integer\"}\n",
                "#@markdown Enter a specific learning rate (e.g., 0.001), or 0.0 to use the config file's value.\n",
                "LEARNING_RATE_OVERRIDE = 0.0 #@param {type:\"number\"}\n",
                "DEVICE_OVERRIDE = \"AUTO\" #@param [\"AUTO\", \"cuda\", \"cpu\", \"mps\"]\n",
                "\n",
                "#@markdown ---\n",
                "#@markdown **Model Architecture (Overrides if specified):**\n",
                "#@markdown LSTM Hidden Size, or -1 for config value.\n",
                "HIDDEN_SIZE_OVERRIDE = -1 #@param {type:\"integer\"}\n",
                "#@markdown Number of LSTM layers, or -1 for config value.\n",
                "NUM_LAYERS_OVERRIDE = -1 #@param {type:\"integer\"}\n",
                "#@markdown Skip Connection: \"AUTO\" (use config), \"ON\", \"OFF\".\n",
                "SKIP_CONNECTION_OVERRIDE = \"AUTO\" #@param [\"AUTO\", \"ON\", \"OFF\"]\n",
                "\n",
                "#@markdown ---\n",
                "#@markdown **Advanced (Overrides if specified):**\n",
                "#@markdown Early stopping patience, or -1 for config value.\n",
                "EARLY_STOPPING_PATIENCE_OVERRIDE = -1 #@param {type:\"integer\"}\n",
                "\n",
                "\n",
                "import json\n",
                "import os\n",
                "import sys\n",
                "\n",
                "print(\"Applying Colab form overrides to the training configuration...\")\n",
                "\n",
                "effective_config_path = globals().get('GLOBAL_COLAB_CONFIG_PATH')\n",
                "\n",
                "if not effective_config_path or not os.path.exists(effective_config_path):\n",
                "    print(f\"ERROR: Effective configuration file '{effective_config_path}' not found.\")\n",
                "    print(\"Please ensure the 'Data Preparation' cell (2.1) was run successfully and GLOBAL_COLAB_CONFIG_PATH was set.\")\n",
                "    sys.exit(\"Effective config not found, cannot apply overrides.\")\n",
                "else:\n",
                "    with open(effective_config_path, 'r') as f:\n",
                "        config_data = json.load(f)\n",
                "    print(f\"Loaded configuration from: {effective_config_path}\")\n",
                "\n",
                "    # Apply overrides from Colab form parameters\n",
                "    if MODEL_NAME_OVERRIDE:\n",
                "        original_model_name = config_data.get('model_name', 'default_model')\n",
                "        config_data['model_name'] = MODEL_NAME_OVERRIDE\n",
                "        # Update output_dir to reflect the new model name if it was based on the old one\n",
                "        model_name_sanitized_original = \"\".join(c if c.isalnum() else \"_\" for c in original_model_name)\n",
                "        expected_original_output_dir = f\"/content/training_output/{model_name_sanitized_original}\"\n",
                "        \n",
                "        model_name_sanitized_new = \"\".join(c if c.isalnum() else \"_\" for c in MODEL_NAME_OVERRIDE)\n",
                "        new_output_dir = f\"/content/training_output/{model_name_sanitized_new}\"\n",
                "        config_data['output_dir'] = new_output_dir\n",
                "        os.makedirs(config_data['output_dir'], exist_ok=True)\n",
                "        print(f\"Overridden model_name to: {MODEL_NAME_OVERRIDE}\")\n",
                "        print(f\"Updated output_dir to: {config_data['output_dir']}\")\n",
                "\n",
                "    if EPOCHS_OVERRIDE != -1:\n",
                "        config_data['epochs'] = EPOCHS_OVERRIDE\n",
                "        print(f\"Overridden epochs to: {EPOCHS_OVERRIDE}\")\n",
                "\n",
                "    if BATCH_SIZE_OVERRIDE != -1:\n",
                "        config_data['batch_size'] = BATCH_SIZE_OVERRIDE\n",
                "        print(f\"Overridden batch_size to: {BATCH_SIZE_OVERRIDE}\")\n",
                "\n",
                "    if LEARNING_RATE_OVERRIDE != 0.0:\n",
                "        config_data['learning_rate'] = LEARNING_RATE_OVERRIDE\n",
                "        print(f\"Overridden learning_rate to: {LEARNING_RATE_OVERRIDE}\")\n",
                "\n",
                "    if DEVICE_OVERRIDE != \"AUTO\":\n",
                "        config_data['device'] = DEVICE_OVERRIDE\n",
                "        print(f\"Overridden device to: {DEVICE_OVERRIDE}\")\n",
                "    \n",
                "    if HIDDEN_SIZE_OVERRIDE != -1:\n",
                "        config_data['hidden_size'] = HIDDEN_SIZE_OVERRIDE\n",
                "        print(f\"Overridden hidden_size to: {HIDDEN_SIZE_OVERRIDE}\")\n",
                "    \n",
                "    if NUM_LAYERS_OVERRIDE != -1:\n",
                "        config_data['num_layers'] = NUM_LAYERS_OVERRIDE\n",
                "        print(f\"Overridden num_layers to: {NUM_LAYERS_OVERRIDE}\")\n",
                "\n",
                "    if SKIP_CONNECTION_OVERRIDE != \"AUTO\":\n",
                "        config_data['skip_connection'] = True if SKIP_CONNECTION_OVERRIDE == \"ON\" else False\n",
                "        print(f\"Overridden skip_connection to: {config_data['skip_connection']}\")\n",
                "\n",
                "    if EARLY_STOPPING_PATIENCE_OVERRIDE != -1:\n",
                "        config_data['early_stopping_patience'] = EARLY_STOPPING_PATIENCE_OVERRIDE\n",
                "        print(f\"Overridden early_stopping_patience to: {EARLY_STOPPING_PATIENCE_OVERRIDE}\")\n",
                "\n",
                "    with open(effective_config_path, 'w') as f:\n",
                "        json.dump(config_data, f, indent=4)\n",
                "    print(f\"Final configuration saved to: {effective_config_path}\")\n",
                "    print(f\"To be used by train_model.py: Model name '{config_data.get('model_name')}', Output dir '{config_data.get('output_dir')}'\")\n",
                "    print(\"\\nTraining Configuration cell complete.\")\n",
                "\n",
                "    globals()['GLOBAL_COLAB_CONFIG_PATH'] = effective_config_path # Ensure it's correctly set for the next cell\n"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": { "id": "run_training_markdown_header" },
            "source": [
                "## 4. Run Training\n\n",
                "This cell executes the `train_model.py` script using the `effective_training_config.json` that was prepared and potentially modified in the previous steps. \n\n",
                "Training progress, including loss values and epoch information, will be displayed in the output of this cell. Depending on the number of epochs, dataset size, and selected device (CPU/GPU), this can take a considerable amount of time."
            ]
        },
        {
            "cell_type": "code",
            "metadata": { "id": "run_training_code_cell" },
            "source": [
                "# Python code for Run Training cell\n",
                "\n",
                "#@markdown ### (RUN CELL) 4.1: Start Model Training\n",
                "#@markdown This cell will execute the `train_model.py` script using the configuration prepared in the previous steps.\n",
                "#@markdown Training progress will be displayed below. This may take a significant amount of time depending on your data and settings.\n",
                "\n",
                "import os\n",
                "import json # For loading the config to show output dir\n",
                "import sys\n",
                "\n",
                "# GLOBAL_COLAB_CONFIG_PATH should have been set by the 'Training Configuration' cell.\n",
                "final_config_path = globals().get('GLOBAL_COLAB_CONFIG_PATH')\n",
                "\n",
                "if not final_config_path or not os.path.exists(final_config_path):\n",
                "    print(f\"ERROR: Final configuration file '{final_config_path}' not found!\")\n",
                "    print(\"Please ensure the 'Data Preparation' (2.1) and 'Training Configuration' (3.1) cells were run successfully.\")\n",
                "    sys.exit(\"Final config not found. Cannot start training.\")\n",
                "else:\n",
                "    print(f\"Starting training using configuration: {final_config_path}\")\n",
                "    \n",
                "    # Ensure we are in the new_model_trainer directory where train_model.py is located.\n",
                "    # The setup cell (1.1) should have handled changing to the correct directory.\n",
                "    # Adding a check here for robustness.\n",
                "    expected_cwd_suffix = \"new_model_trainer\"\n",
                "    if not os.getcwd().endswith(expected_cwd_suffix):\n",
                "        print(f\"WARNING: Current working directory is {os.getcwd()}, not ending with '{expected_cwd_suffix}'.\")\n",
                "        # Attempt to change to the correct directory if the repo was cloned in /content\n",
                "        repo_base_path = \"/content/Automated-GuitarAmpModelling\"\n",
                "        trainer_path = os.path.join(repo_base_path, expected_cwd_suffix)\n",
                "        if os.path.exists(trainer_path):\n",
                "            print(f\"Attempting to change directory to: {trainer_path}\")\n",
                "            os.chdir(trainer_path)\n",
                "            print(f\"New current working directory: {os.getcwd()}\")\n",
                "        else:\n",
                "            print(f\"ERROR: Cannot automatically find or change to directory '{trainer_path}'. Training might fail if train_model.py is not found.\")\n",
                "\n",
                "    # Using '!' to run the shell command and see output directly in Colab\n",
                "    # The output from train_model.py (print statements, tqdm progress bars) will appear here.\n",
                "    get_ipython().system(f'python train_model.py --config_file=\"{final_config_path}\"')\n",
                "\n",
                "    print(\"\\n--- Training Run Attempted ---\")\n",
                "    print(f\"If training started, check the output above for progress and completion status.\")\n",
                "    \n",
                "    # Try to load the config again to get the output_dir and model_name for user feedback\n",
                "    try:\n",
                "        with open(final_config_path, 'r') as f:\n",
                "            final_config_data = json.load(f)\n",
                "        output_dir_from_config = final_config_data.get('output_dir')\n",
                "        model_name_from_config = final_config_data.get('model_name')\n",
                "\n",
                "        if output_dir_from_config and model_name_from_config:\n",
                "            print(f\"Results (checkpoints, logs, .aidax model) should be in: {output_dir_from_config}\")\n",
                "            if os.path.exists(output_dir_from_config):\n",
                "                print(f\"\\nContents of the output directory ({output_dir_from_config}):\")\n",
                "                for item in os.listdir(output_dir_from_config):\n",
                "                    print(f\"- {item}\")\n",
                "                # Check for .aidax file specifically\n",
                "                expected_aidax_path = os.path.join(output_dir_from_config, f\"{model_name_from_config}.aidax\")\n",
                "                if os.path.exists(expected_aidax_path):\n",
                "                    print(f\"\\nSUCCESS: Exported model found at {expected_aidax_path}\")\n",
                "                else:\n",
                "                    print(f\"\\nNOTE: Exported .aidax model not immediately found at {expected_aidax_path}. It might be in a subdirectory if model_name in config was different, or training/export might have failed.\")\n",
                "            else:\n",
                "                print(f\"\\nNOTE: Output directory {output_dir_from_config} specified in config was not found after training attempt.\")\n",
                "        else:\n",
                "            print(\"\\nNOTE: Could not determine output_dir or model_name from config to list results.\")\n",
                "    except Exception as e:\n",
                "        print(f\"Note: Could not list output directory contents due to an error: {e}\")\n"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": { "id": "export_markdown_header"},
            "source": [
                "## 5. Export & Download Model\n\n",
                "After training, the `train_model.py` script automatically exports the best model to the `.aidax` format. This cell helps you locate that file and provides options to download it to your local machine or copy it to a specified folder in your Google Drive."
            ]
        },
        {
            "cell_type": "code",
            "metadata": { "id": "export_code_cell" },
            "source": [
                "# Python code for Export & Download Model cell\n",
                "\n",
                "#@markdown ### (RUN CELL) 5.1: Access Your Trained Model\n",
                "#@markdown This cell helps you locate the exported `.aidax` model file and provides options to download it or copy it to your Google Drive.\n",
                "#@markdown The `.aidax` file should have been generated automatically at the end of a successful training run.\n",
                "\n",
                "#@markdown ---\n",
                "#@markdown **Specify Google Drive Destination (Optional):**\n",
                "#@markdown If you want to copy the `.aidax` file to a specific folder in your Google Drive, enter the path below relative to your Drive's root.\n",
                "#@markdown Example: `MyAidaModels/Exported` (This will be created under `/content/drive/MyDrive/`).\n",
                "#@markdown Leave blank if you only want to download it locally.\n",
                "GDRIVE_EXPORT_SUBDIR = \"AidaX_Models_Exported\" #@param {type:\"string\"}\n",
                "\n",
                "import os\n",
                "import json\n",
                "import shutil\n",
                "import sys\n",
                "from google.colab import files # For downloading\n",
                "\n",
                "print(\"Locating the exported model...\")\n",
                "final_config_path = globals().get('GLOBAL_COLAB_CONFIG_PATH')\n",
                "\n",
                "if not final_config_path or not os.path.exists(final_config_path):\n",
                "    print(f\"ERROR: Final configuration file '{final_config_path}' not found!\")\n",
                "    print(\"Please ensure the entire notebook has been run successfully up to the training step.\")\n",
                "    sys.exit(\"Final config not found.\")\n",
                "else:\n",
                "    try:\n",
                "        with open(final_config_path, 'r') as f:\n",
                "            config_data = json.load(f)\n",
                "        \n",
                "        model_name = config_data.get('model_name')\n",
                "        local_output_dir = config_data.get('output_dir') # This is the local Colab path\n",
                "\n",
                "        if not model_name or not local_output_dir:\n",
                "            print(\"ERROR: 'model_name' or 'output_dir' not found in the configuration.\")\n",
                "            sys.exit(\"Missing critical config info for locating model.\")\n",
                "        \n",
                "        expected_aidax_filename = f\"{model_name}.aidax\"\n",
                "        local_aidax_path = os.path.join(local_output_dir, expected_aidax_filename)\n",
                "\n",
                "        if os.path.exists(local_aidax_path):\n",
                "            print(f\"SUCCESS: Exported model found at: {local_aidax_path}\")\n",
                "            print(f\"File size: {os.path.getsize(local_aidax_path) / 1024:.2f} KB\")\n",
                "\n",
                "            # Option 1: Download the file\n",
                "            print(\"\\n--- Option 1: Download to your local machine ---\")\n",
                "            try:\n",
                "                files.download(local_aidax_path)\n",
                "                print(f\"Download initiated for {expected_aidax_filename}.\")\n",
                "            except Exception as e:\n",
                "                print(f\"Could not initiate download. Error: {e}\")\n",
                "                print(f\"You can manually download it from the Colab file browser (left panel), under: {local_aidax_path}\")\n",
                "\n",
                "            # Option 2: Copy to Google Drive\n",
                "            if GDRIVE_EXPORT_SUBDIR:\n",
                "                drive_base_path = \"/content/drive/MyDrive\"\n",
                "                full_gdrive_export_path = os.path.join(drive_base_path, GDRIVE_EXPORT_SUBDIR)\n",
                "                print(f\"\\n--- Option 2: Copy to Google Drive --- \")\n",
                "                print(f\"Target Google Drive folder: {full_gdrive_export_path}\")\n",
                "                \n",
                "                if not os.path.exists(full_gdrive_export_path):\n",
                "                    print(f\"Google Drive destination path '{full_gdrive_export_path}' does not exist. Attempting to create it.\")\n",
                "                    try:\n",
                "                        os.makedirs(full_gdrive_export_path, exist_ok=True)\n",
                "                        print(f\"Created Google Drive directory: {full_gdrive_export_path}\")\n",
                "                    except Exception as e:\n",
                "                        print(f\"ERROR: Could not create directory on Google Drive: {full_gdrive_export_path}. Error: {e}\")\n",
                "                        # Prevent copy attempt if directory creation failed\n",
                "                        full_gdrive_export_path = None \n",
                "                \n",
                "                if full_gdrive_export_path and os.path.exists(full_gdrive_export_path):\n",
                "                    drive_destination_file_path = os.path.join(full_gdrive_export_path, expected_aidax_filename)\n",
                "                    try:\n",
                "                        shutil.copy(local_aidax_path, drive_destination_file_path)\n",
                "                        print(f\"Model successfully copied to Google Drive: {drive_destination_file_path}\")\n",
                "                    except Exception as e:\n",
                "                        print(f\"ERROR: Failed to copy model to Google Drive. Error: {e}\")\n",
                "                elif full_gdrive_export_path: # Only print if path was attempted\n",
                "                    print(f\"Skipping copy to Google Drive as destination path '{full_gdrive_export_path}' could not be confirmed/created.\")\n",
                "            else:\n",
                "                print(\"\\n--- Option 2: Copy to Google Drive ---\")\n",
                "                print(\"No Google Drive destination subdirectory specified. Skipping copy to Drive.\")\n",
                "        else:\n",
                "            print(f\"ERROR: Exported model file not found at expected location: {local_aidax_path}\")\n",
                "            print(\"This might indicate that the training or export step failed, was not completed, or the model_name/output_dir in your config differs from the training run.\")\n",
                "            print(f\"Please check the output of the 'Run Training' cell and the contents of the expected output directory: {local_output_dir}\")\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"An error occurred while trying to access the model for export/download: {e}\")\n",
                "        print(\"Ensure previous cells, especially training, completed successfully and defined 'GLOBAL_COLAB_CONFIG_PATH'.\")\n",
                "\n",
                "print(\"\\nExport & Download Model cell execution finished.\")"
            ],
            "outputs": []
        }
    ]
}
