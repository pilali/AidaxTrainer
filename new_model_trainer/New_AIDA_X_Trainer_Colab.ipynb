{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "name": "New AIDA-X Model Trainer",
            "provenance": []
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": "# New AIDA-X Model Trainer for Colab"
        },
        {
            "cell_type": "markdown",
            "source": "This notebook allows you to train an AIDA-X compatible neural network model using the `new_model_trainer` scripts directly in Google Colab. \n\n**Instructions:**\n1.  Make a copy of this notebook to your Google Drive (`File > Save a copy in Drive`).\n2.  Follow the steps in each section, executing the code cells.\n3.  Upload your audio data to Google Drive or use the file upload options within Colab where indicated.\n4.  Adjust training parameters as needed using the form fields that will appear when you run certain code cells."
        },
        {
            "cell_type": "markdown",
            "source": "## 1. Setup Environment\n\nThis section clones the repository (if not already present), installs necessary dependencies, and mounts your Google Drive for data access."
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": "# Python and Shell commands for Setup Environment cell\n\n#@markdown ### (RUN CELL) 1.1: Initial Setup, Dependencies, and Google Drive\n#@markdown This cell will:\n#@markdown 1. Clone the repository (if not already in the correct environment).\n#@markdown 2. Change directory to `new_model_trainer`.\n#@markdown 3. Install required Python packages from `requirements.txt`.\n#@markdown 4. Check for GPU and mount Google Drive.\n\nimport os\nimport subprocess\nimport sys\n\n# --- Repository Setup ---\nREPO_NAME = \"Automated-GuitarAmpModelling\" # Assuming this is the repo name\nCOLAB_CONTENT_PATH = \"/content\"\nREPO_PATH = os.path.join(COLAB_CONTENT_PATH, REPO_NAME)\nNEW_TRAINER_DIR = \"new_model_trainer\" # The directory we're working in\nFULL_TRAINER_PATH = os.path.join(REPO_PATH, NEW_TRAINER_DIR)\n\n# Check if we're already in the correct base path (e.g. /content/Automated-GuitarAmpModelling/new_model_trainer)\n# or if the repo needs cloning.\n# This logic assumes the notebook is IN the new_model_trainer directory if the repo is already cloned.\n# If running from a fresh Colab, it will clone.\n\nif os.getcwd() == FULL_TRAINER_PATH:\n    print(f\"Already in the correct directory: {os.getcwd()}\")\n    print(\"Pulling latest changes from repository...\")\n    subprocess.run([\"git\", \"pull\"], check=True, capture_output=True, text=True)\nelif os.path.exists(REPO_PATH):\n    print(f\"Repository '{REPO_NAME}' found at {REPO_PATH}.\")\n    os.chdir(FULL_TRAINER_PATH)\n    print(f\"Changed directory to: {os.getcwd()}\")\n    print(\"Pulling latest changes from repository...\")\n    subprocess.run([\"git\", \"pull\"], check=True, capture_output=True, text=True)\nelse:\n    print(f\"Cloning repository '{REPO_NAME}' into {COLAB_CONTENT_PATH}...\")\n    # Replace with the actual git clone URL of your repository\n    # For example: GIT_CLONE_URL = \"https://github.com/your_username/your_repository.git\"\n    GIT_CLONE_URL = \"https://github.com/AidaDSP/Automated-GuitarAmpModelling.git\" # Using the original repo for now\n    \n    result = subprocess.run([\"git\", \"clone\", GIT_CLONE_URL, REPO_PATH], capture_output=True, text=True)\n    if result.returncode == 0:\n        print(\"Repository cloned successfully.\")\n        os.chdir(FULL_TRAINER_PATH)\n        print(f\"Changed directory to: {os.getcwd()}\")\n    else:\n        print(f\"Error cloning repository: {result.stderr}\")\n        # sys.exit(\"Failed to clone repository.\") # Or raise an exception\n\n# --- Install Dependencies ---\nprint(\"\\nInstalling dependencies from requirements.txt...\")\n# It's good practice to ensure pip is up-to-date first in Colab\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"], check=True, capture_output=True, text=True)\nrequirements_path = \"requirements.txt\" # Assumes it's in the current dir (new_model_trainer)\nif os.path.exists(requirements_path):\n    result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_path], capture_output=True, text=True)\n    if result.returncode == 0:\n        print(\"Dependencies installed successfully.\")\n    else:\n        print(f\"Error installing dependencies: {result.stderr}\")\n        # Consider printing stdout as well for more info: print(result.stdout)\n        # sys.exit(\"Failed to install dependencies.\")\nelse:\n    print(f\"Error: {requirements_path} not found in {os.getcwd()}. Cannot install dependencies.\")\n    # sys.exit(\"requirements.txt not found.\")\n\n# --- PyTorch/CUDA Check (Simplified for Colab) ---\n# Colab runtimes usually come with PyTorch and CUDA pre-installed.\n# Users should select a GPU runtime in Colab (Runtime > Change runtime type > Hardware accelerator > GPU).\nprint(\"\\nChecking PyTorch and GPU availability...\")\ntry:\n    import torch\n    print(f\"PyTorch version: {torch.__version__}\")\n    if torch.cuda.is_available():\n        print(f\"CUDA is available. GPU: {torch.cuda.get_device_name(0)}\")\n        device = torch.device(\"cuda\")\n    elif torch.backends.mps.is_available(): # For Apple Silicon on local Colab (less common)\n        print(\"MPS is available on this device.\")\n        device = torch.device(\"mps\")\n    else:\n        print(\"No GPU found by PyTorch. Training will use CPU.\")\n        device = torch.device(\"cpu\")\nexcept ImportError:\n    print(\"PyTorch is not installed. Please ensure dependencies were installed correctly.\")\n    device = torch.device(\"cpu\") # Fallback\n\n# --- Mount Google Drive ---\nprint(\"\\nMounting Google Drive...\")\ntry:\n    from google.colab import drive\n    drive.mount('/content/drive', force_remount=True) # force_remount can be useful\n    print(\"Google Drive mounted successfully at /content/drive.\")\nexcept ImportError:\n    print(\"Could not import Google Drive module. Are you running in Colab?\")\nexcept Exception as e:\n    print(f\"An error occurred while mounting Google Drive: {e}\")\n\nprint(\"\\nSetup cell complete.\")"
        },
        {
            "cell_type": "markdown",
            "source": "## 2. Data Preparation\n\nSpecify paths to your input (dry) and target (processed) audio files. For conditioned models, you'll also need to define how conditioning parameters are associated with your audio files.\n\n**Option 1: Simple (Non-Conditioned) Data from GDrive**\nIf you have a directory of input files and a directory of target files in your Google Drive."
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": "# Python code for Data Preparation cell\n\n#@markdown ### (RUN CELL) 2.1: Specify Data and Configuration Location\n#@markdown Mount your Google Drive if you haven't already (the Setup cell should do this).\n#@markdown Then, provide the path to your main data directory on Google Drive and the name of your JSON configuration file within that directory.\n\n#@markdown **Important:** Your JSON configuration file (e.g., `my_run_config.json`) should be structured like the `new_model_trainer/configs/example_config.json`.\n#@markdown Specifically, it needs a `dataset_items` list, where each item has `input_path` and `target_path`.\n#@markdown These paths should be **relative to your `DRIVE_DATA_DIR`** or full paths within your Google Drive.\n#@markdown Example: If `DRIVE_DATA_DIR` is `/content/drive/MyDrive/AidaData`, and your config has `input_path: \"DI_audio/input1.wav\"`,\n#@markdown the script will look for `/content/drive/MyDrive/AidaData/DI_audio/input1.wav`.\n\nDRIVE_DATA_DIR = \"/content/drive/MyDrive/AidaX_Training_Data\" #@param {type: \"string\"}\nTRAINING_CONFIG_FILENAME = \"my_training_run_config.json\" #@param {type: \"string\"}\n\nimport os\nimport json\nimport shutil\n\n# --- Define local Colab paths ---\nCOLAB_CONFIG_DIR = \"/content/colab_configs\"\nCOLAB_AUDIO_DIR = \"/content/colab_training_audio\"\nLOCAL_TRAINING_CONFIG_PATH = os.path.join(COLAB_CONFIG_DIR, \"effective_training_config.json\")\n\nos.makedirs(COLAB_CONFIG_DIR, exist_ok=True)\nos.makedirs(COLAB_AUDIO_DIR, exist_ok=True)\n\nprint(f\"User's Google Drive Data Directory: {DRIVE_DATA_DIR}\")\nprint(f\"User's Training Configuration Filename: {TRAINING_CONFIG_FILENAME}\")\n\n# --- Step 1: Copy and Parse the Main JSON Configuration File ---\ndrive_config_path = os.path.join(DRIVE_DATA_DIR, TRAINING_CONFIG_FILENAME)\nlocal_temp_config_path = os.path.join(COLAB_CONFIG_DIR, \"original_drive_config.json\")\n\nif not os.path.exists(drive_config_path):\n    print(f\"ERROR: Main training configuration file not found at: {drive_config_path}\")\n    # sys.exit(\"Configuration file not found.\") # Or raise error\nelse:\n    print(f\"Copying main configuration file from {drive_config_path} to {local_temp_config_path}\")\n    shutil.copy(drive_config_path, local_temp_config_path)\n\n    try:\n        with open(local_temp_config_path, 'r') as f:\n            config_data = json.load(f)\n        print(\"Successfully loaded main configuration file.\")\n    except Exception as e:\n        print(f\"ERROR: Could not parse main training configuration file {local_temp_config_path}. Error: {e}\")\n        # sys.exit(\"Failed to parse configuration.\")\n        config_data = None # Ensure it's defined for later checks\n\nif config_data:\n    # --- Step 2: Process dataset_items, copy audio, and update paths ---\n    if 'dataset_items' not in config_data or not isinstance(config_data['dataset_items'], list):\n        print(\"ERROR: The configuration file must contain a 'dataset_items' list.\")\n        # sys.exit(\"Invalid configuration: missing dataset_items.\")\n    else:\n        updated_dataset_items = []\n        all_files_copied_successfully = True\n        \n        # Clear out old audio data if any\n        for item in os.listdir(COLAB_AUDIO_DIR):\n            item_path = os.path.join(COLAB_AUDIO_DIR, item)\n            if os.path.isfile(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        print(f\"Cleared local audio directory: {COLAB_AUDIO_DIR}\")\n\n        for i, item in enumerate(config_data['dataset_items']):\n            original_input_path = item.get('input_path')\n            original_target_path = item.get('target_path')\n\n            if not original_input_path or not original_target_path:\n                print(f\"WARNING: Skipping item {i} due to missing 'input_path' or 'target_path'.\")\n                continue\n\n            # Determine full path on Drive\n            # Paths in config can be relative to DRIVE_DATA_DIR or absolute Drive paths\n            full_drive_input_path = original_input_path if original_input_path.startswith(\"/content/drive/\") else os.path.join(DRIVE_DATA_DIR, original_input_path)\n            full_drive_target_path = original_target_path if original_target_path.startswith(\"/content/drive/\") else os.path.join(DRIVE_DATA_DIR, original_target_path)\n\n            if not os.path.exists(full_drive_input_path):\n                print(f\"ERROR: Input audio file not found for item {i}: {full_drive_input_path}\")\n                all_files_copied_successfully = False\n                continue\n            if not os.path.exists(full_drive_target_path):\n                print(f\"ERROR: Target audio file not found for item {i}: {full_drive_target_path}\")\n                all_files_copied_successfully = False\n                continue\n            \n            # Create unique local names for audio files to avoid clashes if basenames are identical\n            input_basename = os.path.basename(original_input_path)\n            target_basename = os.path.basename(original_target_path)\n            local_input_filename = f\"{i}_input_{input_basename}\"\n            local_target_filename = f\"{i}_target_{target_basename}\"\n            \n            local_colab_input_path = os.path.join(COLAB_AUDIO_DIR, local_input_filename)\n            local_colab_target_path = os.path.join(COLAB_AUDIO_DIR, local_target_filename)\n\n            # Copy to local Colab environment\n            try:\n                print(f\"Copying input: {full_drive_input_path} -> {local_colab_input_path}\")\n                shutil.copy(full_drive_input_path, local_colab_input_path)\n                print(f\"Copying target: {full_drive_target_path} -> {local_colab_target_path}\")\n                shutil.copy(full_drive_target_path, local_colab_target_path)\n                \n                # Update the item with new local paths\n                updated_item = item.copy()\n                updated_item['input_path'] = local_colab_input_path\n                updated_item['target_path'] = local_colab_target_path\n                updated_dataset_items.append(updated_item)\n            except Exception as e:\n                print(f\"ERROR: Failed to copy files for item {i}. Input: {full_drive_input_path}, Target: {full_drive_target_path}. Error: {e}\")\n                all_files_copied_successfully = False\n                continue\n        \n        if all_files_copied_successfully and updated_dataset_items:\n            config_data['dataset_items'] = updated_dataset_items\n            \n            # --- Step 3: Save the modified config with local paths for train_model.py ---\n            # Also ensure 'output_dir' is a local Colab path\n            original_output_dir = config_data.get('output_dir', 'training_results')\n            # Sanitize model_name to be used as a directory name\n            model_name_sanitized = \"\".join(c if c.isalnum() else \"_\" for c in config_data.get('model_name', 'default_model'))\n            \n            # Always use a local output directory within Colab for results\n            local_output_dir = f\"/content/training_output/{model_name_sanitized}\"\n            config_data['output_dir'] = local_output_dir # Override output_dir to be local\n            os.makedirs(local_output_dir, exist_ok=True)\n            print(f\"Results will be saved to local Colab path: {local_output_dir}\")\n\n            with open(LOCAL_TRAINING_CONFIG_PATH, 'w') as f:\n                json.dump(config_data, f, indent=4)\n            print(f\"Effective training configuration with local paths saved to: {LOCAL_TRAINING_CONFIG_PATH}\")\n            print(\"\\nData preparation cell complete. You can now proceed to 'Training Configuration'.\")\n        elif not updated_dataset_items:\n            print(\"ERROR: No dataset items were successfully processed. Please check paths and file existence in your Google Drive and config.\")\n        else:\n            print(\"ERROR: Some files could not be copied. Please check error messages above.\")\nelse:\n    print(\"ERROR: Main configuration data not loaded. Cannot proceed with data preparation.\")\n\n# Expose the path to the generated config for the next cells\nGLOBAL_COLAB_CONFIG_PATH = LOCAL_TRAINING_CONFIG_PATH if config_data and 'dataset_items' in config_data else None\n"
        },
        {
            "cell_type": "markdown",
            "source": "## 3. Training Configuration\n\nDefine the training parameters. These will be written to a JSON configuration file (`colab_config.json`) which will be used by `train_model.py`."
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": "# Python code for Training Configuration cell\n\n#@markdown ### (RUN CELL) 3.1: Adjust Training Parameters (Optional Overrides)\n#@markdown This section allows you to override some common settings from your main configuration file (`{{TRAINING_CONFIG_FILENAME}}` loaded in the previous step).\n#@markdown Leave fields blank or as their default to use the value from your JSON config.\n\n#@markdown ---\n#@markdown **Basic Settings:**\nMODEL_NAME_OVERRIDE = \"\" #@param {type:\"string\"}\n#@markdown Enter a specific number of epochs, or -1 to use the config file's value.\nEPOCHS_OVERRIDE = -1 #@param {type:\"integer\"}\n#@markdown Enter a specific batch size, or -1 to use the config file's value.\nBATCH_SIZE_OVERRIDE = -1 #@param {type:\"integer\"}\n#@markdown Enter a specific learning rate (e.g., 0.001), or 0.0 to use the config file's value.\nLEARNING_RATE_OVERRIDE = 0.0 #@param {type:\"number\"}\nDEVICE_OVERRIDE = \"AUTO\" #@param [\"AUTO\", \"cuda\", \"cpu\", \"mps\"]\n\n#@markdown ---\n#@markdown **Model Architecture (Overrides if specified):**\n#@markdown LSTM Hidden Size, or -1 for config value.\nHIDDEN_SIZE_OVERRIDE = -1 #@param {type:\"integer\"}\n#@markdown Number of LSTM layers, or -1 for config value.\nNUM_LAYERS_OVERRIDE = -1 #@param {type:\"integer\"}\n#@markdown Skip Connection: \"AUTO\" (use config), \"ON\", \"OFF\".\nSKIP_CONNECTION_OVERRIDE = \"AUTO\" #@param [\"AUTO\", \"ON\", \"OFF\"]\n\n#@markdown ---\n#@markdown **Advanced (Overrides if specified):**\n#@markdown Early stopping patience, or -1 for config value.\nEARLY_STOPPING_PATIENCE_OVERRIDE = -1 #@param {type:\"integer\"}\n\n\nimport json\nimport os\n\nprint(\"Applying Colab form overrides to the training configuration...\")\n\n# Path to the configuration file prepared by the Data Preparation cell\n# GLOBAL_COLAB_CONFIG_PATH should have been set by the previous cell.\n# If not, we default, but it's expected to be there.\neffective_config_path = globals().get('GLOBAL_COLAB_CONFIG_PATH', '/content/colab_configs/effective_training_config.json')\n\nif not os.path.exists(effective_config_path):\n    print(f\"ERROR: Effective configuration file '{effective_config_path}' not found.\")\n    print(\"Please ensure the 'Data Preparation' cell (2.1) was run successfully.\")\n    # sys.exit(\"Effective config not found.\") # Or raise\nelse:\n    with open(effective_config_path, 'r') as f:\n        config_data = json.load(f)\n    print(f\"Loaded configuration from: {effective_config_path}\")\n\n    # Apply overrides from Colab form parameters\n    if MODEL_NAME_OVERRIDE:\n        config_data['model_name'] = MODEL_NAME_OVERRIDE\n        # Also update the output_dir to reflect the new model name\n        model_name_sanitized = \"\".join(c if c.isalnum() else \"_\" for c in MODEL_NAME_OVERRIDE)\n        config_data['output_dir'] = f\"/content/training_output/{model_name_sanitized}\" \n        os.makedirs(config_data['output_dir'], exist_ok=True)\n        print(f\"Overridden model_name to: {MODEL_NAME_OVERRIDE}, output_dir to: {config_data['output_dir']}\")\n\n\n    if EPOCHS_OVERRIDE != -1:\n        config_data['epochs'] = EPOCHS_OVERRIDE\n        print(f\"Overridden epochs to: {EPOCHS_OVERRIDE}\")\n\n    if BATCH_SIZE_OVERRIDE != -1:\n        config_data['batch_size'] = BATCH_SIZE_OVERRIDE\n        print(f\"Overridden batch_size to: {BATCH_SIZE_OVERRIDE}\")\n\n    if LEARNING_RATE_OVERRIDE != 0.0:\n        config_data['learning_rate'] = LEARNING_RATE_OVERRIDE\n        print(f\"Overridden learning_rate to: {LEARNING_RATE_OVERRIDE}\")\n\n    if DEVICE_OVERRIDE != \"AUTO\":\n        config_data['device'] = DEVICE_OVERRIDE\n        print(f\"Overridden device to: {DEVICE_OVERRIDE}\")\n    \n    # Model architecture overrides\n    if HIDDEN_SIZE_OVERRIDE != -1:\n        config_data['hidden_size'] = HIDDEN_SIZE_OVERRIDE\n        print(f\"Overridden hidden_size to: {HIDDEN_SIZE_OVERRIDE}\")\n    \n    if NUM_LAYERS_OVERRIDE != -1:\n        config_data['num_layers'] = NUM_LAYERS_OVERRIDE\n        print(f\"Overridden num_layers to: {NUM_LAYERS_OVERRIDE}\")\n\n    if SKIP_CONNECTION_OVERRIDE != \"AUTO\":\n        config_data['skip_connection'] = True if SKIP_CONNECTION_OVERRIDE == \"ON\" else False\n        print(f\"Overridden skip_connection to: {config_data['skip_connection']}\")\n\n    if EARLY_STOPPING_PATIENCE_OVERRIDE != -1:\n        config_data['early_stopping_patience'] = EARLY_STOPPING_PATIENCE_OVERRIDE\n        print(f\"Overridden early_stopping_patience to: {EARLY_STOPPING_PATIENCE_OVERRIDE}\")\n\n    # Save the potentially modified configuration back\n    # This ensures the 'Run Training' cell uses these latest settings.\n    with open(effective_config_path, 'w') as f:\n        json.dump(config_data, f, indent=4)\n    print(f\"Final configuration saved to: {effective_config_path}\")\n    print(f\"Final model name for this run: {config_data.get('model_name', 'N/A')}\")\n    print(f\"Output directory for this run: {config_data.get('output_dir', 'N/A')}\")\n    print(\"\\nTraining Configuration cell complete.\")\n\n# Make sure GLOBAL_COLAB_CONFIG_PATH is still set for the next cell\nglobals()['GLOBAL_COLAB_CONFIG_PATH'] = effective_config_path\n"
        },
        {
            "cell_type": "markdown",
            "source": "## 4. Run Training\n\nThis cell executes the `train_model.py` script using the configuration defined above."
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": "# Python code for Run Training cell\n\n#@markdown ### (RUN CELL) 4.1: Start Model Training\n#@markdown This cell will execute the `train_model.py` script using the configuration prepared in the previous steps.\n#@markdown Training progress will be displayed below. This may take a significant amount of time depending on your data and settings.\n\nimport os\n\n# GLOBAL_COLAB_CONFIG_PATH should have been set by the 'Training Configuration' cell.\n# Default if somehow not set, though it should be.\nfinal_config_path = globals().get('GLOBAL_COLAB_CONFIG_PATH', '/content/colab_configs/effective_training_config.json')\n\nif not os.path.exists(final_config_path):\n    print(f\"ERROR: Final configuration file '{final_config_path}' not found!\")\n    print(\"Please ensure the 'Data Preparation' (2.1) and 'Training Configuration' (3.1) cells were run successfully.\")\n    # sys.exit(\"Final config not found.\") # Or raise\nelse:\n    print(f\"Starting training using configuration: {final_config_path}\")\n    # Ensure we are in the new_model_trainer directory where train_model.py is located\n    # The setup cell should have cd'd into new_model_trainer.\n    # If not, an explicit os.chdir might be needed here, but it's better if setup cell handles it.\n    # current_dir = os.getcwd()\n    # expected_dir_fragment = \"new_model_trainer\" \n    # if not current_dir.endswith(expected_dir_fragment):\n    #     print(f\"Warning: Current directory is {current_dir}. Ensure train_model.py is accessible or change dir.\")\n\n    # Using '!' to run the shell command and see output directly in Colab\n    # The output from train_model.py (print statements, tqdm progress bars) will appear here.\n    !python train_model.py --config_file=\"{final_config_path}\"\n\n    print(\"\\n--- Training Run Attempted ---\")\n    print(f\"If training started, check the output above for progress and completion status.\")\n    print(f\"Results (checkpoints, logs, .aidax model) should be in the 'output_dir' specified in your config, typically under /content/training_output/YOUR_MODEL_NAME/\")\n\n    # For convenience, try to list the contents of the output directory if it exists\n    # This requires knowing the output_dir from the config. We can load it again.\n    import json\n    try:\n        with open(final_config_path, 'r') as f:\n            final_config_data = json.load(f)\n        output_dir_from_config = final_config_data.get('output_dir')\n        if output_dir_from_config and os.path.exists(output_dir_from_config):\n            print(f\"\\nContents of the output directory ({output_dir_from_config}):\")\n            for item in os.listdir(output_dir_from_config):\n                print(f\"- {item}\")\n            # Check for .aidax file\n            model_name_from_config = final_config_data.get('model_name')\n            expected_aidax_path = os.path.join(output_dir_from_config, f\"{model_name_from_config}.aidax\")\n            if os.path.exists(expected_aidax_path):\n                print(f\"\\nSUCCESS: Exported model found at {expected_aidax_path}\")\n            else:\n                print(f\"\\nNOTE: Exported .aidax model not immediately found at {expected_aidax_path}. It might be in a subdirectory or training/export might have failed.\")\n        elif output_dir_from_config:\n            print(f\"\\nNOTE: Output directory {output_dir_from_config} specified in config was not found after training.\")\n        else:\n            print(\"\\nNOTE: Could not determine output_dir from config to list results.\")\n\n    except Exception as e:\n        print(f\"Note: Could not list output directory contents due to an error: {e}\")\n"
        },
        {
            "cell_type": "markdown",
            "source": "## 5. Export & Download Model\n\nAfter training, the best model is typically exported to `.aidax` format. This section helps you locate and download it."
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": "# Python code for Export & Download Model cell\n\n#@markdown ### (RUN CELL) 5.1: Access Your Trained Model\n#@markdown This cell helps you locate the exported `.aidax` model file and provides options to download it or copy it to your Google Drive.\n#@markdown The `.aidax` file should have been generated automatically at the end of a successful training run.\n\n#@markdown ---\n#@markdown **Specify Google Drive Destination (Optional):**\n#@markdown If you want to copy the `.aidax` file to a specific folder in your Google Drive, enter the path below.\n#@markdown Example: `/content/drive/MyDrive/MyAidaModels/` (ensure this folder exists).\n#@markdown Leave blank if you only want to download it locally.\nGDRIVE_EXPORT_COPY_PATH = \"\" #@param {type:\"string\"}\n\nimport os\nimport json\nimport shutil\nfrom google.colab import files # For downloading\n\n# GLOBAL_COLAB_CONFIG_PATH should have been set by the 'Training Configuration' cell.\nfinal_config_path = globals().get('GLOBAL_COLAB_CONFIG_PATH', '/content/colab_configs/effective_training_config.json')\n\nif not os.path.exists(final_config_path):\n    print(f\"ERROR: Final configuration file '{final_config_path}' not found!\")\n    print(\"Please ensure the entire notebook has been run up to the training step.\")\n    # sys.exit(\"Final config not found.\") # Or raise\nelse:\n    try:\n        with open(final_config_path, 'r') as f:\n            config_data = json.load(f)\n        \n        model_name = config_data.get('model_name')\n        # The output_dir in the config should already be the local Colab path, e.g., /content/training_output/MODEL_NAME\n        local_output_dir = config_data.get('output_dir')\n\n        if not model_name or not local_output_dir:\n            print(\"ERROR: 'model_name' or 'output_dir' not found in the configuration.\")\n            # sys.exit(\"Missing critical config info.\")\n        else:\n            expected_aidax_filename = f\"{model_name}.aidax\"\n            local_aidax_path = os.path.join(local_output_dir, expected_aidax_filename)\n\n            if os.path.exists(local_aidax_path):\n                print(f\"SUCCESS: Exported model found at: {local_aidax_path}\")\n                print(f\"File size: {os.path.getsize(local_aidax_path) / 1024:.2f} KB\")\n\n                # Option 1: Download the file\n                print(\"\\n--- Option 1: Download to your local machine ---\")\n                try:\n                    files.download(local_aidax_path)\n                    print(f\"Download initiated for {expected_aidax_filename}.\")\n                except Exception as e:\n                    print(f\"Could not initiate download. Error: {e}\")\n                    print(\"You can manually download it from the Colab file browser (left panel), under:\")\n                    print(local_aidax_path)\n\n                # Option 2: Copy to Google Drive\n                if GDRIVE_EXPORT_COPY_PATH:\n                    print(f\"\\n--- Option 2: Copy to Google Drive ---\")\n                    if not os.path.exists(GDRIVE_EXPORT_COPY_PATH):\n                        print(f\"Warning: Google Drive destination path '{GDRIVE_EXPORT_COPY_PATH}' does not exist. Attempting to create it.\")\n                        try:\n                            os.makedirs(GDRIVE_EXPORT_COPY_PATH, exist_ok=True)\n                            print(f\"Created Google Drive directory: {GDRIVE_EXPORT_COPY_PATH}\")\n                        except Exception as e:\n                            print(f\"ERROR: Could not create directory on Google Drive: {GDRIVE_EXPORT_COPY_PATH}. Error: {e}\")\n                            # Don't proceed with copy if dir creation failed\n                            # sys.exit(\"Drive path creation failed.\")\n                    \n                    if os.path.exists(GDRIVE_EXPORT_COPY_PATH): # Check again if it was created or already existed\n                        drive_destination_path = os.path.join(GDRIVE_EXPORT_COPY_PATH, expected_aidax_filename)\n                        try:\n                            shutil.copy(local_aidax_path, drive_destination_path)\n                            print(f\"Model copied to Google Drive: {drive_destination_path}\")\n                        except Exception as e:\n                            print(f\"ERROR: Failed to copy model to Google Drive. Error: {e}\")\n                    else:\n                        print(f\"Skipping copy to Google Drive as destination path '{GDRIVE_EXPORT_COPY_PATH}' could not be confirmed/created.\")\n                else:\n                    print(\"\\n--- Option 2: Copy to Google Drive ---\")\n                    print(\"No Google Drive destination path specified. Skipping copy to Drive.\")\n            else:\n                print(f\"ERROR: Exported model file not found at expected location: {local_aidax_path}\")\n                print(\"This might indicate that the training or export step failed or was not completed.\")\n                print(f\"Please check the output of the 'Run Training' cell and the contents of {local_output_dir}\")\n\n    except Exception as e:\n        print(f\"An error occurred while trying to access the model for export/download: {e}\")\n        print(\"Ensure previous cells, especially training, completed successfully.\")\n\nprint(\"\\nExport & Download Model cell execution finished.\")\n"
        }
    ]
}

[end of new_model_trainer/New_AIDA_X_Trainer_Colab.ipynb]
